{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fa87fb",
   "metadata": {},
   "source": [
    "# Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "022c1e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoreload enabled - modules will refresh automatically when files change\n",
      "If autoreload doesn't work, run: reload_modules()\n",
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable automatic reloading of modules\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Alternative manual reload function for when autoreload doesn't work\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "def reload_modules():\n",
    "    \"\"\"Manually reload custom modules\"\"\"\n",
    "    modules_to_reload = ['Python.Inventory', 'Python.Filtering', 'Python.Duplicates', 'Python.Read_Files']\n",
    "    \n",
    "    for module_name in modules_to_reload:\n",
    "        if module_name in sys.modules:\n",
    "            importlib.reload(sys.modules[module_name])\n",
    "            print(f\"Reloaded: {module_name}\")\n",
    "    print(\"Manual reload complete!\")\n",
    "\n",
    "print(\"Autoreload enabled - modules will refresh automatically when files change\")\n",
    "print(\"If autoreload doesn't work, run: reload_modules()\")\n",
    "\n",
    "# Test autoreload status\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1e6bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded: Python.Inventory\n",
      "Reloaded: Python.Filtering\n",
      "Reloaded: Python.Read_Files\n",
      "Manual reload complete!\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "reload_modules()\n",
    "from Python.Read_Files import read_csv_dataframe, read_excel_dataframe, save_excel_dataframe, save_csv_dataframe\n",
    "from Python.Filtering import quantity_outliers_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cb6830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79800 entries, 0 to 79799\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   PN                            79800 non-null  object \n",
      " 1   CONDITION_CODE                79800 non-null  object \n",
      " 2   PNM_AUTO_KEY                  79800 non-null  int64  \n",
      " 3   PCC_AUTO_KEY                  79800 non-null  int64  \n",
      " 4   COUNT_DATA_POINTS_PN_PC       79705 non-null  float64\n",
      " 5   LATEST_DATA_POINT_DATE_PN_PC  79705 non-null  object \n",
      " 6   NATTY_FMV                     79705 non-null  float64\n",
      " 7   SYNTH_FMV                     1120 non-null   float64\n",
      " 8   FMV                           79800 non-null  float64\n",
      " 9   CONFIDENCE_PN_PC              79800 non-null  object \n",
      " 10  FMV_SOURCE                    79800 non-null  object \n",
      "dtypes: float64(4), int64(2), object(5)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from Python.Read_Files import read_csv_dataframe\n",
    "\n",
    "input_dir = Path(\"Input\")\n",
    "file_name_FMV = \"Part numbers with fair market value.csv\"\n",
    "csv_path = input_dir / file_name_FMV\n",
    "FMV_DF = read_csv_dataframe(csv_path)\n",
    "FMV_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1509269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 CSV files:\n",
      "  - report_2025-09-29T145010.csv\n",
      "  - report_2025-09-29T145248.csv\n",
      "  - report_2025-09-29T145327.csv\n",
      "  - report_2025-09-29T145804.csv\n",
      "  - report_2025-09-29T150053.csv\n",
      "  - report_2025-09-29T150112.csv\n",
      "  - report_2025-09-29T150138.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmarek\\AppData\\Local\\Temp\\ipykernel_27036\\145321618.py:22: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read report_2025-09-29T145010.csv: 373550 rows, 23 columns\n",
      "Successfully read report_2025-09-29T145248.csv: 203259 rows, 23 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmarek\\AppData\\Local\\Temp\\ipykernel_27036\\145321618.py:22: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read report_2025-09-29T145327.csv: 257270 rows, 23 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmarek\\AppData\\Local\\Temp\\ipykernel_27036\\145321618.py:22: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read report_2025-09-29T145804.csv: 176143 rows, 23 columns\n",
      "Successfully read report_2025-09-29T150053.csv: 227130 rows, 23 columns\n",
      "Successfully read report_2025-09-29T150112.csv: 211036 rows, 23 columns\n",
      "Successfully read report_2025-09-29T150138.csv: 112691 rows, 23 columns\n",
      "\n",
      "Combined dataframe created:\n",
      "Total rows: 1561079\n",
      "Total columns: 23\n",
      "Files combined: 7\n",
      "\n",
      "Column names:\n",
      "  - Rotabull RFQ ID\n",
      "  - Source RFQ ID\n",
      "  - Received At (UTC)\n",
      "  - Priority\n",
      "  - Buyer Company Name\n",
      "  - Buyer Company Address\n",
      "  - Buyer Company Country\n",
      "  - Buyer Industry\n",
      "  - Buyer Contact Name\n",
      "  - Buyer Contact Email\n",
      "  - RFQ Status\n",
      "  - RFQ Source\n",
      "  - RFQ Type\n",
      "  - Part Number\n",
      "  - Condition Code\n",
      "  - Quantity\n",
      "  - Alternate Part Number\n",
      "  - Description\n",
      "  - ILS Flag Description\n",
      "  - Service Requested\n",
      "  - Assigned User\n",
      "  - Assigned Team\n",
      "  - source_file\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rotabull RFQ ID</th>\n",
       "      <th>Source RFQ ID</th>\n",
       "      <th>Received At (UTC)</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Buyer Company Name</th>\n",
       "      <th>Buyer Company Address</th>\n",
       "      <th>Buyer Company Country</th>\n",
       "      <th>Buyer Industry</th>\n",
       "      <th>Buyer Contact Name</th>\n",
       "      <th>Buyer Contact Email</th>\n",
       "      <th>...</th>\n",
       "      <th>Part Number</th>\n",
       "      <th>Condition Code</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Alternate Part Number</th>\n",
       "      <th>Description</th>\n",
       "      <th>ILS Flag Description</th>\n",
       "      <th>Service Requested</th>\n",
       "      <th>Assigned User</th>\n",
       "      <th>Assigned Team</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27824322</td>\n",
       "      <td>ILSCAWF250328192447</td>\n",
       "      <td>2025-03-29 00:27:23</td>\n",
       "      <td>Routine</td>\n",
       "      <td>AVTRADE LIMITED</td>\n",
       "      <td>WEST SUSSEX, ENG, UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harry Chalfont</td>\n",
       "      <td>harry.chalfont@avtrade.com</td>\n",
       "      <td>...</td>\n",
       "      <td>3215302-4</td>\n",
       "      <td>OH</td>\n",
       "      <td>1</td>\n",
       "      <td>3215302-5</td>\n",
       "      <td>VALVE, HIGH PRESSURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27824322</td>\n",
       "      <td>ILSCAWF250328192447</td>\n",
       "      <td>2025-03-29 00:27:23</td>\n",
       "      <td>Routine</td>\n",
       "      <td>AVTRADE LIMITED</td>\n",
       "      <td>WEST SUSSEX, ENG, UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harry Chalfont</td>\n",
       "      <td>harry.chalfont@avtrade.com</td>\n",
       "      <td>...</td>\n",
       "      <td>3215302-5</td>\n",
       "      <td>OH</td>\n",
       "      <td>1</td>\n",
       "      <td>3215302-4</td>\n",
       "      <td>VALVE, HIGH PRESSURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27824730</td>\n",
       "      <td>M27</td>\n",
       "      <td>2025-03-29 03:36:46</td>\n",
       "      <td>Expedite</td>\n",
       "      <td>PIONEER AERO SUPPLY</td>\n",
       "      <td>CHICAGO, IL, UNITED STATES</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patrick Armstrong</td>\n",
       "      <td>parmstrong@pioneer-aero.com</td>\n",
       "      <td>...</td>\n",
       "      <td>326975</td>\n",
       "      <td>SV</td>\n",
       "      <td>1</td>\n",
       "      <td>No Alt. PN</td>\n",
       "      <td>VALVE, ON/OFF, ANTI-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North America</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27824796</td>\n",
       "      <td>ILSCGK0250328224116</td>\n",
       "      <td>2025-03-29 03:43:17</td>\n",
       "      <td>Expedite</td>\n",
       "      <td>Airbay</td>\n",
       "      <td>Solomejos Neries 9-54, Vilnius, 06317, Lithuania</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam Kupcevic</td>\n",
       "      <td>operations@airbayaviation.com</td>\n",
       "      <td>...</td>\n",
       "      <td>754D0000-01</td>\n",
       "      <td>OH</td>\n",
       "      <td>1</td>\n",
       "      <td>754A0000-03</td>\n",
       "      <td>HEAT EXCHANGER, MAIN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27824796</td>\n",
       "      <td>ILSCGK0250328224116</td>\n",
       "      <td>2025-03-29 03:43:17</td>\n",
       "      <td>Expedite</td>\n",
       "      <td>Airbay</td>\n",
       "      <td>Solomejos Neries 9-54, Vilnius, 06317, Lithuania</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam Kupcevic</td>\n",
       "      <td>operations@airbayaviation.com</td>\n",
       "      <td>...</td>\n",
       "      <td>755C0000-01</td>\n",
       "      <td>OH</td>\n",
       "      <td>1</td>\n",
       "      <td>754D0000-01</td>\n",
       "      <td>REHEATER ASSY, AIR C</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rotabull RFQ ID        Source RFQ ID    Received At (UTC)  Priority  \\\n",
       "0         27824322  ILSCAWF250328192447  2025-03-29 00:27:23   Routine   \n",
       "1         27824322  ILSCAWF250328192447  2025-03-29 00:27:23   Routine   \n",
       "2         27824730                  M27  2025-03-29 03:36:46  Expedite   \n",
       "3         27824796  ILSCGK0250328224116  2025-03-29 03:43:17  Expedite   \n",
       "4         27824796  ILSCGK0250328224116  2025-03-29 03:43:17  Expedite   \n",
       "\n",
       "    Buyer Company Name                             Buyer Company Address  \\\n",
       "0      AVTRADE LIMITED                  WEST SUSSEX, ENG, UNITED KINGDOM   \n",
       "1      AVTRADE LIMITED                  WEST SUSSEX, ENG, UNITED KINGDOM   \n",
       "2  PIONEER AERO SUPPLY                        CHICAGO, IL, UNITED STATES   \n",
       "3               Airbay  Solomejos Neries 9-54, Vilnius, 06317, Lithuania   \n",
       "4               Airbay  Solomejos Neries 9-54, Vilnius, 06317, Lithuania   \n",
       "\n",
       "  Buyer Company Country Buyer Industry Buyer Contact Name  \\\n",
       "0        UNITED KINGDOM            NaN     Harry Chalfont   \n",
       "1        UNITED KINGDOM            NaN     Harry Chalfont   \n",
       "2         UNITED STATES            NaN  Patrick Armstrong   \n",
       "3             Lithuania            NaN      Adam Kupcevic   \n",
       "4             Lithuania            NaN      Adam Kupcevic   \n",
       "\n",
       "             Buyer Contact Email  ...  Part Number Condition Code Quantity  \\\n",
       "0     harry.chalfont@avtrade.com  ...    3215302-4             OH        1   \n",
       "1     harry.chalfont@avtrade.com  ...    3215302-5             OH        1   \n",
       "2    parmstrong@pioneer-aero.com  ...       326975             SV        1   \n",
       "3  operations@airbayaviation.com  ...  754D0000-01             OH        1   \n",
       "4  operations@airbayaviation.com  ...  755C0000-01             OH        1   \n",
       "\n",
       "  Alternate Part Number           Description  ILS Flag Description  \\\n",
       "0             3215302-5  VALVE, HIGH PRESSURE                   NaN   \n",
       "1             3215302-4  VALVE, HIGH PRESSURE                   NaN   \n",
       "2            No Alt. PN  VALVE, ON/OFF, ANTI-                   NaN   \n",
       "3           754A0000-03  HEAT EXCHANGER, MAIN                   Yes   \n",
       "4           754D0000-01  REHEATER ASSY, AIR C                   Yes   \n",
       "\n",
       "  Service Requested Assigned User  Assigned Team                   source_file  \n",
       "0               NaN           NaN            NaN  report_2025-09-29T145010.csv  \n",
       "1               NaN           NaN            NaN  report_2025-09-29T145010.csv  \n",
       "2               NaN           NaN  North America  report_2025-09-29T145010.csv  \n",
       "3               NaN           NaN            NaN  report_2025-09-29T145010.csv  \n",
       "4               NaN           NaN            NaN  report_2025-09-29T145010.csv  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read and combine all report CSV files from Input/Data/\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the path to the data directory\n",
    "data_dir = Path(\"Input/Data\")\n",
    "\n",
    "# Find all CSV files that start with \"report_2025-09-29\"\n",
    "csv_pattern = str(data_dir / \"report_2025-09-29*.csv\")\n",
    "csv_files = glob.glob(csv_pattern)\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files:\")\n",
    "for file in csv_files:\n",
    "    print(f\"  - {Path(file).name}\")\n",
    "\n",
    "# Read and combine all CSV files into one dataframe\n",
    "combined_dataframes = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        # Add a column to track which file this data came from\n",
    "        df['source_file'] = Path(csv_file).name\n",
    "        combined_dataframes.append(df)\n",
    "        print(f\"Successfully read {Path(csv_file).name}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {Path(csv_file).name}: {e}\")\n",
    "\n",
    "# Combine all dataframes\n",
    "if combined_dataframes:\n",
    "    combined_report_df = pd.concat(combined_dataframes, ignore_index=True)\n",
    "    print(f\"\\nCombined dataframe created:\")\n",
    "    print(f\"Total rows: {len(combined_report_df)}\")\n",
    "    print(f\"Total columns: {len(combined_report_df.columns)}\")\n",
    "    print(f\"Files combined: {combined_report_df['source_file'].nunique()}\")\n",
    "    \n",
    "    # Show basic info about the combined dataframe\n",
    "    print(f\"\\nColumn names:\")\n",
    "    for col in combined_report_df.columns:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    display(combined_report_df.head())\n",
    "else:\n",
    "    print(\"No CSV files were successfully read!\")\n",
    "    combined_report_df = pd.DataFrame()  # Create empty dataframe as fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c29bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rotabull_df = combined_report_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91950b83",
   "metadata": {},
   "source": [
    "# Remove Duplicates within a span of a 2 days and removing quantities that are unrealistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "433b2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Output\\Rotabull_DeDuplicates.csv already exists. Loading existing file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmarek\\Documents\\Project_Files\\Rotabull Data Export 1 Year\\Data_Pre_Processes\\Python\\Read_Files.py:10: DtypeWarning: Columns (7,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(p)\n"
     ]
    }
   ],
   "source": [
    "from Python.Filtering import day2_duplicates\n",
    "from pathlib import Path\n",
    "\n",
    "filename_duplicates = \"Rotabull_DeDuplicates.csv\"\n",
    "output_path = Path(\"Output\") / filename_duplicates\n",
    "\n",
    "if output_path.exists():\n",
    "    print(f\"File {output_path} already exists. Loading existing file...\")\n",
    "    Rotabull_df_dedup = read_csv_dataframe(output_path)\n",
    "else:\n",
    "    print(f\"File {output_path} does not exist. Running day2_duplicates...\")\n",
    "    Rotabull_df_dedup = day2_duplicates(Rotabull_df, filename_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98aae886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping: c:\\Users\\mmarek\\Documents\\Project_Files\\Rotabull Data Export 1 Year\\Data_Pre_Processes\\Output\\Rotabull_DeDuplicates.csv\n"
     ]
    }
   ],
   "source": [
    "save_csv_dataframe(Rotabull_df_dedup, filename_duplicates)\n",
    "Rotabull_df = Rotabull_df_dedup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e026c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Output\\Rotabull_NonOutliers.csv does not exist. Running quantity_outliers_improved...\n",
      "Starting improved quantity outlier detection...\n",
      "Global quantity statistics:\n",
      "  Median: 1\n",
      "  95th percentile: 12\n",
      "  99th percentile: 80\n",
      "  99.9th percentile: 500\n",
      "Progressive outlier detection results:\n",
      "  Original rows: 1,299,632\n",
      "  Removed outliers: 1,964\n",
      "  Final rows: 1,297,668\n",
      "  Removal rate: 0.15%\n",
      "\n",
      "Parts with outliers removed (669 parts):\n",
      "  002A0003-45 (LOW): removed 1 quantities [40000]\n",
      "    → threshold: ≤ 5.0 | median=1, iqr=19999.5\n",
      "  024147-000 (LOW): removed 1 quantities [70]\n",
      "    → threshold: ≤ 50.0 | median=1, iqr=1.0\n",
      "  025-1156-001 (LOW): removed 2 quantities [100, 108]\n",
      "    → threshold: ≤ 85.0 | median=2, iqr=14.0\n",
      "  025-1157-001 (LOW): removed 1 quantities [200]\n",
      "    → threshold: ≤ 50.0 | median=1, iqr=7.8\n",
      "  02607025AIR (LOW): removed 1 quantities [250]\n",
      "    → threshold: ≤ 80.0 | median=4, iqr=14.2\n",
      "  0320KPU01 (LOW): removed 2 quantities [5000, 5000]\n",
      "    → threshold: ≤ 80.0 | median=1, iqr=0.0\n",
      "  045-250-025 (LOW): removed 1 quantities [200]\n",
      "    → threshold: ≤ 50.0 | median=1, iqr=1.0\n",
      "  066-50014-0202 (LOW): removed 1 quantities [300]\n",
      "    → threshold: ≤ 50.0 | median=1, iqr=0.0\n",
      "  0F25-021 (LOW): removed 9 quantities [100, 200, 200, 200, 400, 125, 100, 230, 230]\n",
      "    → threshold: ≤ 80.0 | median=4, iqr=18.0\n",
      "  0U301537 (LOW): removed 1 quantities [100]\n",
      "    → threshold: ≤ 10.0 | median=1, iqr=0.0\n",
      "  ... and 659 more parts\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "filename_nonoutliers = \"Rotabull_NonOutliers.csv\"\n",
    "output_path = Path(\"Output\") / filename_nonoutliers\n",
    "\n",
    "if output_path.exists():\n",
    "    print(f\"File {output_path} already exists. Loading existing file...\")\n",
    "    Rotabull_df_nonoutliers = read_csv_dataframe(output_path)\n",
    "else:\n",
    "    print(f\"File {output_path} does not exist. Running quantity_outliers_improved...\")\n",
    "    Rotabull_df_nonoutliers = quantity_outliers_improved(Rotabull_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13cabb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving DataFrame to: Rotabull_NonOutliers.csv\n",
      "Saved DataFrame to: c:\\Users\\mmarek\\Documents\\Project_Files\\Rotabull Data Export 1 Year\\Data_Pre_Processes\\Output\\Rotabull_NonOutliers.csv\n"
     ]
    }
   ],
   "source": [
    "save_csv_dataframe(Rotabull_df_nonoutliers, filename_nonoutliers)\n",
    "Rotabull_df = Rotabull_df_nonoutliers.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067daa83",
   "metadata": {},
   "source": [
    "# Finding Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6545dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Output\\DF_Inventory_Snowflake.csv already exists. Loading existing file...\n"
     ]
    }
   ],
   "source": [
    "from Python.Inventory import findInventory\n",
    "\n",
    "filename_inventory = \"DF_Inventory_Snowflake.csv\"\n",
    "output_path = Path(\"Output\") / filename_inventory\n",
    "\n",
    "if output_path.exists():\n",
    "    print(f\"File {output_path} already exists. Loading existing file...\")\n",
    "    DF_Inventory = read_csv_dataframe(output_path)\n",
    "else:\n",
    "    print(f\"File {output_path} does not exist. Running findInventory...\")\n",
    "    DF_Inventory = findInventory(Rotabull_df, filename_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b557e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping: c:\\Users\\mmarek\\Documents\\Project_Files\\Rotabull Data Export 1 Year\\Data_Pre_Processes\\Output\\DF_Inventory_Snowflake.csv\n"
     ]
    }
   ],
   "source": [
    "save_csv_dataframe(DF_Inventory, filename_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c70d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rotabull_df_copy = Rotabull_df.copy()\n",
    "DF_Inventory_copy = DF_Inventory.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90c8ba",
   "metadata": {},
   "source": [
    "# Finding Inventory based on Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "241a4d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmarek\\AppData\\Local\\Temp\\ipykernel_27036\\927723356.py:3: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(series, errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotabull: Created 'Received_Date' (date only). Nulls: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmarek\\AppData\\Local\\Temp\\ipykernel_27036\\927723356.py:3: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(series, errors=\"coerce\", infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF_Inventory: Created 'SNAP_DATE_date' (date only). Nulls: 0\n"
     ]
    }
   ],
   "source": [
    "def to_date_only(series):\n",
    "    # parse to datetime (coerce invalids to NaT) then keep only the date part\n",
    "    dt = pd.to_datetime(series, errors=\"coerce\", infer_datetime_format=True)\n",
    "    return dt.dt.date\n",
    "\n",
    "# Rotabull copy: Received At (UTC) -> Received_Date (date only)\n",
    "if \"Received At (UTC)\" in Rotabull_df_copy.columns:\n",
    "    Rotabull_df_copy[\"Received_Date\"] = to_date_only(Rotabull_df_copy[\"Received At (UTC)\"])\n",
    "    print(\"Rotabull: Created 'Received_Date' (date only). Nulls:\", Rotabull_df_copy[\"Received_Date\"].isna().sum())\n",
    "else:\n",
    "    print(\"Rotabull: column 'Received At (UTC)' not found\")\n",
    "\n",
    "# DF_Inventory copy: SNAP_DATE -> SNAP_DATE_date (date only)\n",
    "if \"SNAP_DATE\" in DF_Inventory_copy.columns:\n",
    "    DF_Inventory_copy[\"SNAP_DATE_date\"] = to_date_only(DF_Inventory_copy[\"SNAP_DATE\"])\n",
    "    print(\"DF_Inventory: Created 'SNAP_DATE_date' (date only). Nulls:\", DF_Inventory_copy[\"SNAP_DATE_date\"].isna().sum())\n",
    "else:\n",
    "    print(\"DF_Inventory: column 'SNAP_DATE' not found\")\n",
    "\n",
    "# Quick sanity checks (show a few values)\n",
    "# print(\"Rotabull sample dates:\", Rotabull_df_copy[\"Received_Date\"].dropna().unique()[:5])\n",
    "# print(\"DF_Inventory sample dates:\", DF_Inventory_copy[\"SNAP_DATE_date\"].dropna().unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad1334a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'Stock' column to Rotabull_df_copy (1297668 rows). Sample:\n",
      "       Part Number Received_Date Stock\n",
      "0        3215302-4    2025-03-29    NS\n",
      "1        3215302-5    2025-03-29    NS\n",
      "2           326975    2025-03-29    NS\n",
      "3      754D0000-01    2025-03-29    NS\n",
      "4      755C0000-01    2025-03-29    NS\n",
      "5          767669B    2025-03-29    NS\n",
      "6   D5311047700007    2025-03-29    NS\n",
      "7     D53132010000    2025-03-29    NS\n",
      "8     664700500A4D    2025-03-29    NS\n",
      "9  80-178-03-88013    2025-03-29    NS\n"
     ]
    }
   ],
   "source": [
    "Rotabull_df_copy[\"Part_norm\"] = Rotabull_df_copy[\"Part Number\"].astype(str).str.strip()\n",
    "DF_Inventory_copy[\"PN_norm\"] = DF_Inventory_copy[\"P/N\"].astype(str).str.strip()\n",
    "\n",
    "# ensure date-only columns exist and are actual date objects\n",
    "# (assumes the to_date_only step ran earlier and created Received_Date and SNAP_DATE_date)\n",
    "# coerce Qty Available to numeric for aggregation\n",
    "DF_Inventory_copy[\"Qty Available\"] = pd.to_numeric(DF_Inventory_copy.get(\"Qty Available\"), errors=\"coerce\")\n",
    "\n",
    "# aggregate inventory by part and date (sum quantity available for that day)\n",
    "inv_daily = (\n",
    "    DF_Inventory_copy\n",
    "    .dropna(subset=[\"PN_norm\", \"SNAP_DATE_date\"])\n",
    "    .groupby([\"PN_norm\", \"SNAP_DATE_date\"], as_index=False)[\"Qty Available\"]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# merge inventory totals into rotabull rows on part + date\n",
    "merged = Rotabull_df_copy.merge(\n",
    "    inv_daily,\n",
    "    left_on=[\"Part_norm\", \"Received_Date\"],\n",
    "    right_on=[\"PN_norm\", \"SNAP_DATE_date\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_inv\")\n",
    ")\n",
    "\n",
    "# format Stock: numeric where found, 'NS' where not\n",
    "def _format_stock(x):\n",
    "    if pd.isna(x):\n",
    "        return \"NS\"\n",
    "    try:\n",
    "        f = float(x)\n",
    "    except Exception:\n",
    "        return \"NS\"\n",
    "    if f.is_integer():\n",
    "        return int(f)\n",
    "    return round(f, 2)\n",
    "\n",
    "merged[\"Stock\"] = merged[\"Qty Available\"].apply(_format_stock)\n",
    "\n",
    "# copy Stock back to Rotabull_df_copy_price and clean helper cols\n",
    "Rotabull_df_copy[\"Stock\"] = merged[\"Stock\"].values\n",
    "\n",
    "# optional: drop helper normalization columns if not needed\n",
    "Rotabull_df_copy.drop(columns=[\"Part_norm\"], inplace=True, errors=\"ignore\")\n",
    "DF_Inventory_copy.drop(columns=[\"PN_norm\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(f\"Added 'Stock' column to Rotabull_df_copy ({Rotabull_df_copy.shape[0]} rows). Sample:\")\n",
    "print(Rotabull_df_copy[[\"Part Number\", \"Received_Date\", \"Stock\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9388da79",
   "metadata": {},
   "source": [
    "# Whether no stock or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c91e045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 'Stock' to follow 'Quantity'.\n"
     ]
    }
   ],
   "source": [
    "df_temp1 = Rotabull_df_copy  # alias for readability\n",
    "\n",
    "if \"Stock\" not in df_temp1.columns:\n",
    "    print(\"Column 'Stock' not found in dataframe.\")\n",
    "else:\n",
    "    # candidate names for the quantity column (extend if needed)\n",
    "    qty_candidates = [\"Quantity\", \"Qty\", \"Quantity Received\", \"Qty Received\", \"Qty Received (EA)\"]\n",
    "    cols = df_temp1.columns.tolist()\n",
    "\n",
    "    # find the first matching quantity column present\n",
    "    qty_col = next((c for c in qty_candidates if c in cols), None)\n",
    "\n",
    "    if qty_col:\n",
    "        # remove Stock then insert it right after the qty_col\n",
    "        cols.remove(\"Stock\")\n",
    "        insert_idx = cols.index(qty_col) + 1\n",
    "        cols.insert(insert_idx, \"Stock\")\n",
    "        df_temp1 = df_temp1.loc[:, cols]\n",
    "        print(f\"Moved 'Stock' to follow '{qty_col}'.\")\n",
    "    else:\n",
    "        # fallback: put Stock next to Part Number if Quantity not found\n",
    "        if \"Part Number\" in cols:\n",
    "            cols.remove(\"Stock\")\n",
    "            insert_idx = cols.index(\"Part Number\") + 1\n",
    "            cols.insert(insert_idx, \"Stock\")\n",
    "            df_temp1 = df_temp1.loc[:, cols]\n",
    "            print(\"Quantity column not found — placed 'Stock' after 'Part Number' instead.\")\n",
    "        else:\n",
    "            print(\"No suitable column found to place 'Stock' next to. Leaving column order unchanged.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3012f320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rotabull RFQ ID</th>\n",
       "      <th>Source RFQ ID</th>\n",
       "      <th>Received At (UTC)</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Buyer Company Name</th>\n",
       "      <th>Buyer Company Address</th>\n",
       "      <th>Buyer Company Country</th>\n",
       "      <th>Buyer Industry</th>\n",
       "      <th>Buyer Contact Name</th>\n",
       "      <th>Buyer Contact Email</th>\n",
       "      <th>...</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Alternate Part Number</th>\n",
       "      <th>Description</th>\n",
       "      <th>ILS Flag Description</th>\n",
       "      <th>Service Requested</th>\n",
       "      <th>Assigned User</th>\n",
       "      <th>Assigned Team</th>\n",
       "      <th>source_file</th>\n",
       "      <th>Received_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27824322</td>\n",
       "      <td>ILSCAWF250328192447</td>\n",
       "      <td>2025-03-29 00:27:23</td>\n",
       "      <td>Routine</td>\n",
       "      <td>AVTRADE LIMITED</td>\n",
       "      <td>WEST SUSSEX, ENG, UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harry Chalfont</td>\n",
       "      <td>harry.chalfont@avtrade.com</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NS</td>\n",
       "      <td>3215302-5</td>\n",
       "      <td>VALVE, HIGH PRESSURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27824322</td>\n",
       "      <td>ILSCAWF250328192447</td>\n",
       "      <td>2025-03-29 00:27:23</td>\n",
       "      <td>Routine</td>\n",
       "      <td>AVTRADE LIMITED</td>\n",
       "      <td>WEST SUSSEX, ENG, UNITED KINGDOM</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harry Chalfont</td>\n",
       "      <td>harry.chalfont@avtrade.com</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NS</td>\n",
       "      <td>3215302-4</td>\n",
       "      <td>VALVE, HIGH PRESSURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27824730</td>\n",
       "      <td>M27</td>\n",
       "      <td>2025-03-29 03:36:46</td>\n",
       "      <td>Expedite</td>\n",
       "      <td>PIONEER AERO SUPPLY</td>\n",
       "      <td>CHICAGO, IL, UNITED STATES</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patrick Armstrong</td>\n",
       "      <td>parmstrong@pioneer-aero.com</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NS</td>\n",
       "      <td>No Alt. PN</td>\n",
       "      <td>VALVE, ON/OFF, ANTI-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North America</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27824796</td>\n",
       "      <td>ILSCGK0250328224116</td>\n",
       "      <td>2025-03-29 03:43:17</td>\n",
       "      <td>Expedite</td>\n",
       "      <td>Airbay</td>\n",
       "      <td>Solomejos Neries 9-54, Vilnius, 06317, Lithuania</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam Kupcevic</td>\n",
       "      <td>operations@airbayaviation.com</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NS</td>\n",
       "      <td>754A0000-03</td>\n",
       "      <td>HEAT EXCHANGER, MAIN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27824796</td>\n",
       "      <td>ILSCGK0250328224116</td>\n",
       "      <td>2025-03-29 03:43:17</td>\n",
       "      <td>Expedite</td>\n",
       "      <td>Airbay</td>\n",
       "      <td>Solomejos Neries 9-54, Vilnius, 06317, Lithuania</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam Kupcevic</td>\n",
       "      <td>operations@airbayaviation.com</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NS</td>\n",
       "      <td>754D0000-01</td>\n",
       "      <td>REHEATER ASSY, AIR C</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>report_2025-09-29T145010.csv</td>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rotabull RFQ ID        Source RFQ ID    Received At (UTC)  Priority  \\\n",
       "0         27824322  ILSCAWF250328192447  2025-03-29 00:27:23   Routine   \n",
       "1         27824322  ILSCAWF250328192447  2025-03-29 00:27:23   Routine   \n",
       "2         27824730                  M27  2025-03-29 03:36:46  Expedite   \n",
       "3         27824796  ILSCGK0250328224116  2025-03-29 03:43:17  Expedite   \n",
       "4         27824796  ILSCGK0250328224116  2025-03-29 03:43:17  Expedite   \n",
       "\n",
       "    Buyer Company Name                             Buyer Company Address  \\\n",
       "0      AVTRADE LIMITED                  WEST SUSSEX, ENG, UNITED KINGDOM   \n",
       "1      AVTRADE LIMITED                  WEST SUSSEX, ENG, UNITED KINGDOM   \n",
       "2  PIONEER AERO SUPPLY                        CHICAGO, IL, UNITED STATES   \n",
       "3               Airbay  Solomejos Neries 9-54, Vilnius, 06317, Lithuania   \n",
       "4               Airbay  Solomejos Neries 9-54, Vilnius, 06317, Lithuania   \n",
       "\n",
       "  Buyer Company Country Buyer Industry Buyer Contact Name  \\\n",
       "0        UNITED KINGDOM            NaN     Harry Chalfont   \n",
       "1        UNITED KINGDOM            NaN     Harry Chalfont   \n",
       "2         UNITED STATES            NaN  Patrick Armstrong   \n",
       "3             Lithuania            NaN      Adam Kupcevic   \n",
       "4             Lithuania            NaN      Adam Kupcevic   \n",
       "\n",
       "             Buyer Contact Email  ... Quantity Stock Alternate Part Number  \\\n",
       "0     harry.chalfont@avtrade.com  ...        1    NS             3215302-5   \n",
       "1     harry.chalfont@avtrade.com  ...        1    NS             3215302-4   \n",
       "2    parmstrong@pioneer-aero.com  ...        1    NS            No Alt. PN   \n",
       "3  operations@airbayaviation.com  ...        1    NS           754A0000-03   \n",
       "4  operations@airbayaviation.com  ...        1    NS           754D0000-01   \n",
       "\n",
       "            Description ILS Flag Description  Service Requested Assigned User  \\\n",
       "0  VALVE, HIGH PRESSURE                  NaN                NaN           NaN   \n",
       "1  VALVE, HIGH PRESSURE                  NaN                NaN           NaN   \n",
       "2  VALVE, ON/OFF, ANTI-                  NaN                NaN           NaN   \n",
       "3  HEAT EXCHANGER, MAIN                  Yes                NaN           NaN   \n",
       "4  REHEATER ASSY, AIR C                  Yes                NaN           NaN   \n",
       "\n",
       "   Assigned Team                   source_file Received_Date  \n",
       "0            NaN  report_2025-09-29T145010.csv    2025-03-29  \n",
       "1            NaN  report_2025-09-29T145010.csv    2025-03-29  \n",
       "2  North America  report_2025-09-29T145010.csv    2025-03-29  \n",
       "3            NaN  report_2025-09-29T145010.csv    2025-03-29  \n",
       "4            NaN  report_2025-09-29T145010.csv    2025-03-29  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Rotabull_df = df_temp1.copy()\n",
    "Rotabull_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf656e2d",
   "metadata": {},
   "source": [
    "# customer data (uncertain on implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd4718c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmarek\\AppData\\Roaming\\Python\\Python313\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "customer_path = Path(\"Input/customer_data.xlsx\")\n",
    "customer_df = read_excel_dataframe(customer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1ce35",
   "metadata": {},
   "source": [
    "# FINAL FILE SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1cf17aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Output\\Rotabull_Data_Processed.csv already exists. Skipping save operation.\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"Output\") / \"Rotabull_Data_Processed.csv\"\n",
    "\n",
    "if output_path.exists():\n",
    "    print(f\"File {output_path} already exists. Skipping save operation.\")\n",
    "else:\n",
    "    save_csv_dataframe(Rotabull_df, \"Rotabull_Data_Processed.csv\")\n",
    "    print(f\"File saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
